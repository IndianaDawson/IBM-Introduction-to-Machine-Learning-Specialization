{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "run_control": {
                    "marked": true
                }
            },
            "source": "# Machine Learning Foundation\n\n## Course 4, Part e: Non-Negative Matrix Factorization DEMO"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This exercise illustrates usage of Non-negative Matrix factorization and covers techniques related to sparse matrices and some basic work with Natural Langauge Processing.  We will use NMF to look at the top words for given topics."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Data"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We'll be using the BBC dataset. These are articles collected from 5 different topics, with the data pre-processed. \n\nThese data are available in the data folder (or online [here](http://mlg.ucd.ie/files/datasets/bbc.zip)). The data consists of a few files. The steps we'll be following are:\n\n* *bbc.terms* is just a list of words \n* *bbc.docs* is a list of artcles listed by topic.\n\nAt a high level, we're going to \n\n1. Turn the `bbc.mtx` file into a sparse matrix (a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html) format can be useful for matrices with many values that are 0, and save space by storing the position and values of non-zero elements).\n1. Decompose that sparse matrix using NMF.\n1. Use the resulting components of NMF to analyze the topics that result."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Data Setup"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns, os\nimport types\nfrom botocore.client import Config\nimport ibm_boto3\n\n# Going to import bbc.mtx, bbc.terms, and bbc.docs into the notebook"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "def download_file_cos(credentials,local_file_name,key):  \n    cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n    try:\n        res=cos.download_file(Bucket=credentials['BUCKET'],Key=key,Filename=local_file_name)\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print('The file %s has been downloaded into this notebook' % key)"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The file bbc.mtx has been downloaded into this notebook\n"
                }
            ],
            "source": "# For local file, input the name of what you want the file to be, for the key put name of the file on Cloud Object Storage\n# it would be best if they match for ease\ndownload_file_cos(credentials_1,'bbc.mtx','bbc.mtx')"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The file bbc.terms has been downloaded into this notebook\n"
                }
            ],
            "source": "# For local file, input the name of what you want the file to be, for the key put name of the file on Cloud Object Storage\n# it would be best if they match for ease\ndownload_file_cos(credentials_2,'bbc.terms','bbc.terms')"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The file bbc.docs has been downloaded into this notebook\n"
                }
            ],
            "source": "# For local file, input the name of what you want the file to be, for the key put name of the file on Cloud Object Storage\n# it would be best if they match for ease\ndownload_file_cos(credentials_3,'bbc.docs','bbc.docs')"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "with open('bbc.mtx') as f:\n    content = f.readlines()"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "'9635 2225 286774\\n'"
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# remove top 2 rows, not needed\ncontent.pop(0)\ncontent.pop(0)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Part 1\n\nHere, we will turn this into a list of tuples representing a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html). Remember the description of the file from above:\n\n* *bbc.mtx* is a list: first column is **wordID**, second is **articleID** and the third is the number of times that word appeared in that article.\n\nSo, if word 1 appears in article 3, 2 times, one element of our list will be:\n\n`(1, 3, 2)`"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "[(1, 1, 1),\n (1, 7, 2),\n (1, 11, 1),\n (1, 14, 1),\n (1, 15, 2),\n (1, 19, 2),\n (1, 21, 1),\n (1, 29, 1)]"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "sparsemat = [tuple(map(int,map(float,c.split()))) for c in content]\n# Let's examine the first few elements\nsparsemat[:8]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Part 2: Preparing Sparse Matrix data for NMF "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We will use the [coo matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html) function to turn the sparse matrix into an array. "
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "import numpy as np\nfrom scipy.sparse import coo_matrix\n#subtracting one from each for rows and columns as each value at 1 and Python at 0\nrows =   [x[1]-1 for x in sparsemat]\ncols =   [x[0]-1 for x in sparsemat]\nvalues = [x[2] for x in sparsemat]\ncoo =    coo_matrix((values, (rows, cols)))"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "with open('bbc.terms') as f:\n    content = f.readlines()\nwords = [c.split()[0] for c in content]"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "with open('bbc.docs') as f:\n    content = f.readlines()\ndocs  = [c.split()[0] for c in content]"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ad</th>\n      <th>sale</th>\n      <th>boost</th>\n      <th>time</th>\n      <th>warner</th>\n      <th>profit</th>\n      <th>quarterli</th>\n      <th>media</th>\n      <th>giant</th>\n      <th>jump</th>\n      <th>...</th>\n      <th>\u00a3339</th>\n      <th>denialofservic</th>\n      <th>ddo</th>\n      <th>seagrav</th>\n      <th>bot</th>\n      <th>wirelessli</th>\n      <th>streamcast</th>\n      <th>peripher</th>\n      <th>headphon</th>\n      <th>flavour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>business.001</th>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>10</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>business.002</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>business.003</th>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>business.004</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>business.005</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>tech.397</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>tech.398</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>tech.399</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>tech.400</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>tech.401</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows \u00d7 9635 columns</p>\n</div>",
                        "text/plain": "              ad  sale  boost  time  warner  profit  quarterli  media  giant  \\\nbusiness.001   1     5      2     3       4      10          1      1      1   \nbusiness.002   0     0      1     2       0       0          0      0      0   \nbusiness.003   0     4      0     0       0       0          0      0      1   \nbusiness.004   0     1      0     0       0       4          1      0      0   \nbusiness.005   0     0      0     1       0       0          0      0      1   \ntech.397       0     0      0     0       0       0          0      0      0   \ntech.398       0     0      0     1       0       1          0      1      0   \ntech.399       0     0      0     1       0       0          0      0      0   \ntech.400       0     0      0     0       0       0          0      0      0   \ntech.401       0     1      0    22       0       0          0      0      0   \n\n              jump  ...  \u00a3339  denialofservic  ddo  seagrav  bot  wirelessli  \\\nbusiness.001     1  ...     0               0    0        0    0           0   \nbusiness.002     0  ...     0               0    0        0    0           0   \nbusiness.003     0  ...     0               0    0        0    0           0   \nbusiness.004     0  ...     0               0    0        0    0           0   \nbusiness.005     0  ...     0               0    0        0    0           0   \ntech.397         0  ...     0               0    0        0    0           0   \ntech.398         0  ...     0               0    0        0    0           0   \ntech.399         0  ...     0               0    0        0    0           0   \ntech.400         0  ...     0               0    0        0    0           0   \ntech.401         0  ...     0               0    0        0    0           0   \n\n              streamcast  peripher  headphon  flavour  \nbusiness.001           0         0         0        0  \nbusiness.002           0         0         0        0  \nbusiness.003           0         0         0        0  \nbusiness.004           0         0         0        0  \nbusiness.005           0         0         0        0  \ntech.397               0         0         0        0  \ntech.398               0         0         0        0  \ntech.399               0         0         0        0  \ntech.400               0         0         0        0  \ntech.401               0         0         0        0  \n\n[10 rows x 9635 columns]"
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df = pd.DataFrame(coo.toarray(), columns = words, index = docs)\ndf.head(5).append(df.tail(5))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## NMF"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "NMF is a way of decomposing a matrix of documents and words so that one of the matrices can be interpreted as the \"loadings\" or \"weights\" of each word on a topic. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Check out [the NMF documentation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) and the [examples of topic extraction using NMF and LDA](http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html)."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Part 3\n\nHere, we will import `NMF`, define a model object with 5 components, and `fit_transform` the data created above."
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(2225, 5)"
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.decomposition import NMF\nmodel = NMF(n_components=5, init='random', random_state=818)\ndoc_topic = model.fit_transform(coo)\n\ndoc_topic.shape\n# we should have 2225 observations (articles) and five latent features"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 1, 1, ..., 3, 3, 2])"
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# find feature with highest value per doc\nnp.argmax(doc_topic, axis=1)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Part 4: \n\nCheck out the `components` of this model:"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(5, 9635)"
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "model.components_.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "This is five rows, each of which is a \"topic\" containing the weights of each word on that topic. The exercise is to _get a list of the top 10 words for each topic_. We can just store this in a list of lists."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Note:** Just like we read in the data above, we'll have to read in the words from the `bbc.terms` file."
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": "# with open('bbc.terms') as f:\n#     content = f.readlines()\n# words = [c.split()[0] for c in content]"
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": "topic_words = []\nfor r in model.components_:\n    a = sorted([(v,i) for i,v in enumerate(r)],reverse=True)[0:12]\n    topic_words.append([words[e[1]] for e in a])"
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>parti</td>\n      <td>labour</td>\n      <td>govern</td>\n      <td>elect</td>\n      <td>blair</td>\n      <td>peopl</td>\n      <td>tori</td>\n      <td>minist</td>\n      <td>plan</td>\n      <td>brown</td>\n      <td>sai</td>\n      <td>told</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>year</td>\n      <td>increas</td>\n      <td>wage</td>\n      <td>compani</td>\n      <td>busi</td>\n      <td>minimum</td>\n      <td>govern</td>\n      <td>rate</td>\n      <td>market</td>\n      <td>economi</td>\n      <td>pai</td>\n      <td>rise</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>game</td>\n      <td>plai</td>\n      <td>time</td>\n      <td>player</td>\n      <td>world</td>\n      <td>first</td>\n      <td>win</td>\n      <td>get</td>\n      <td>go</td>\n      <td>on</td>\n      <td>england</td>\n      <td>two</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>peopl</td>\n      <td>mobil</td>\n      <td>phone</td>\n      <td>technolog</td>\n      <td>servic</td>\n      <td>music</td>\n      <td>digit</td>\n      <td>user</td>\n      <td>network</td>\n      <td>on</td>\n      <td>tv</td>\n      <td>system</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>best</td>\n      <td>song</td>\n      <td>music</td>\n      <td>year</td>\n      <td>award</td>\n      <td>film</td>\n      <td>25</td>\n      <td>angel</td>\n      <td>robbi</td>\n      <td>british</td>\n      <td>think</td>\n      <td>vote</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "      0        1       2          3       4        5       6       7   \\\n0  parti   labour  govern      elect   blair    peopl    tori  minist   \n1   year  increas    wage    compani    busi  minimum  govern    rate   \n2   game     plai    time     player   world    first     win     get   \n3  peopl    mobil   phone  technolog  servic    music   digit    user   \n4   best     song   music       year   award     film      25   angel   \n\n        8        9        10      11  \n0     plan    brown      sai    told  \n1   market  economi      pai    rise  \n2       go       on  england     two  \n3  network       on       tv  system  \n4    robbi  british    think    vote  "
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# Here, each set of words relates to the corresponding topic (ie the first set of words relates to topic 'Business', etc.)\npd.DataFrame(topic_words[:5])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The original data had 5 topics, as listed in `bbc.docs` (which these topic words relate to). \n\n```\nBusiness\nEntertainment\nPolitics\nSport\nTech\n```\n\nIn \"real life\", we would have found a way to use these to inform the model. But for this little demo, we can just compare the recovered topics to the original ones. And they seem to match reasonably well. The order is different, which is to be expected in this kind of model."
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "['business.001\\n',\n 'business.002\\n',\n 'business.003\\n',\n 'business.004\\n',\n 'business.005\\n',\n 'business.006\\n',\n 'business.007\\n',\n 'business.008\\n']"
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "with open('bbc.docs') as d:\n    doc_content = d.readlines()\n    \ndoc_content[:8]"
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ad</th>\n      <th>sale</th>\n      <th>boost</th>\n      <th>time</th>\n      <th>warner</th>\n      <th>profit</th>\n      <th>quarterli</th>\n      <th>media</th>\n      <th>giant</th>\n      <th>jump</th>\n      <th>...</th>\n      <th>\u00a3339</th>\n      <th>denialofservic</th>\n      <th>ddo</th>\n      <th>seagrav</th>\n      <th>bot</th>\n      <th>wirelessli</th>\n      <th>streamcast</th>\n      <th>peripher</th>\n      <th>headphon</th>\n      <th>flavour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>topic_1</th>\n      <td>1.110</td>\n      <td>0.000</td>\n      <td>0.148</td>\n      <td>1.805</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.290</td>\n      <td>0.000</td>\n      <td>0.008</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.00</td>\n      <td>0.004</td>\n      <td>0.005</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>topic_2</th>\n      <td>0.907</td>\n      <td>2.135</td>\n      <td>0.556</td>\n      <td>1.620</td>\n      <td>0.015</td>\n      <td>1.233</td>\n      <td>0.091</td>\n      <td>0.059</td>\n      <td>0.347</td>\n      <td>0.206</td>\n      <td>...</td>\n      <td>0.001</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.002</td>\n      <td>0.002</td>\n      <td>0.000</td>\n      <td>0.001</td>\n    </tr>\n    <tr>\n      <th>topic_3</th>\n      <td>0.678</td>\n      <td>0.412</td>\n      <td>0.051</td>\n      <td>4.003</td>\n      <td>0.038</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.190</td>\n      <td>0.084</td>\n      <td>0.128</td>\n      <td>...</td>\n      <td>0.001</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.002</td>\n      <td>0.005</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>topic_4</th>\n      <td>0.696</td>\n      <td>0.416</td>\n      <td>0.055</td>\n      <td>1.220</td>\n      <td>0.052</td>\n      <td>0.051</td>\n      <td>0.008</td>\n      <td>1.221</td>\n      <td>0.280</td>\n      <td>0.000</td>\n      <td>...</td>\n      <td>0.025</td>\n      <td>0.02</td>\n      <td>0.061</td>\n      <td>0.075</td>\n      <td>0.136</td>\n      <td>0.021</td>\n      <td>0.040</td>\n      <td>0.029</td>\n      <td>0.028</td>\n      <td>0.020</td>\n    </tr>\n    <tr>\n      <th>topic_5</th>\n      <td>0.475</td>\n      <td>0.373</td>\n      <td>0.124</td>\n      <td>0.986</td>\n      <td>0.022</td>\n      <td>0.042</td>\n      <td>0.000</td>\n      <td>0.052</td>\n      <td>0.021</td>\n      <td>0.252</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.00</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.005</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 9635 columns</p>\n</div>",
                        "text/plain": "            ad   sale  boost   time  warner  profit  quarterli  media  giant  \\\ntopic_1  1.110  0.000  0.148  1.805   0.000   0.000      0.000  0.290  0.000   \ntopic_2  0.907  2.135  0.556  1.620   0.015   1.233      0.091  0.059  0.347   \ntopic_3  0.678  0.412  0.051  4.003   0.038   0.000      0.000  0.190  0.084   \ntopic_4  0.696  0.416  0.055  1.220   0.052   0.051      0.008  1.221  0.280   \ntopic_5  0.475  0.373  0.124  0.986   0.022   0.042      0.000  0.052  0.021   \n\n          jump  ...   \u00a3339  denialofservic    ddo  seagrav    bot  wirelessli  \\\ntopic_1  0.008  ...  0.000            0.00  0.004    0.005  0.000       0.000   \ntopic_2  0.206  ...  0.001            0.00  0.000    0.000  0.000       0.000   \ntopic_3  0.128  ...  0.001            0.00  0.000    0.000  0.000       0.000   \ntopic_4  0.000  ...  0.025            0.02  0.061    0.075  0.136       0.021   \ntopic_5  0.252  ...  0.000            0.00  0.000    0.000  0.000       0.000   \n\n         streamcast  peripher  headphon  flavour  \ntopic_1       0.000     0.000     0.000    0.000  \ntopic_2       0.002     0.002     0.000    0.001  \ntopic_3       0.000     0.002     0.005    0.000  \ntopic_4       0.040     0.029     0.028    0.020  \ntopic_5       0.005     0.000     0.000    0.000  \n\n[5 rows x 9635 columns]"
                    },
                    "execution_count": 23,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "topic_word = pd.DataFrame(model.components_.round(3),\n             index = [\"topic_1\",\"topic_2\",\"topic_3\",\"topic_4\",\"topic_5\"],\n             columns = words)\ntopic_word"
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_1</th>\n      <th>topic_2</th>\n      <th>topic_3</th>\n      <th>topic_4</th>\n      <th>topic_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>business</th>\n      <td>0.00000</td>\n      <td>0.27757</td>\n      <td>0.00680</td>\n      <td>0.08380</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>business</th>\n      <td>0.03033</td>\n      <td>0.31001</td>\n      <td>0.00311</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>business</th>\n      <td>0.03685</td>\n      <td>0.17981</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>business</th>\n      <td>0.00000</td>\n      <td>0.40197</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00982</td>\n    </tr>\n    <tr>\n      <th>business</th>\n      <td>0.00061</td>\n      <td>0.14514</td>\n      <td>0.00890</td>\n      <td>0.03643</td>\n      <td>0.00765</td>\n    </tr>\n    <tr>\n      <th>tech</th>\n      <td>0.00000</td>\n      <td>0.10331</td>\n      <td>0.00000</td>\n      <td>0.37516</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>tech</th>\n      <td>0.02170</td>\n      <td>0.05943</td>\n      <td>0.00000</td>\n      <td>0.29394</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>tech</th>\n      <td>0.25508</td>\n      <td>0.22328</td>\n      <td>0.03813</td>\n      <td>0.26931</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>tech</th>\n      <td>0.05870</td>\n      <td>0.09831</td>\n      <td>0.00509</td>\n      <td>0.15505</td>\n      <td>0.00511</td>\n    </tr>\n    <tr>\n      <th>tech</th>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>3.86234</td>\n      <td>0.06373</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "          topic_1  topic_2  topic_3  topic_4  topic_5\nbusiness  0.00000  0.27757  0.00680  0.08380  0.00000\nbusiness  0.03033  0.31001  0.00311  0.00000  0.00000\nbusiness  0.03685  0.17981  0.00000  0.00000  0.00000\nbusiness  0.00000  0.40197  0.00000  0.00000  0.00982\nbusiness  0.00061  0.14514  0.00890  0.03643  0.00765\ntech      0.00000  0.10331  0.00000  0.37516  0.00000\ntech      0.02170  0.05943  0.00000  0.29394  0.00000\ntech      0.25508  0.22328  0.03813  0.26931  0.00000\ntech      0.05870  0.09831  0.00509  0.15505  0.00511\ntech      0.00000  0.00000  3.86234  0.06373  0.00000"
                    },
                    "execution_count": 24,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "topic_doc = pd.DataFrame(doc_topic.round(5),\n            index = [i.split(\".\")[0] for i in docs],\n            columns = [\"topic_1\",\"topic_2\",\"topic_3\",\"topic_4\",\"topic_5\"])\ntopic_doc.head(5).append(topic_doc.tail(5))"
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "topic_1         politics\ntopic_2         business\ntopic_3            sport\ntopic_4             tech\ntopic_5    entertainment\ndtype: object"
                    },
                    "execution_count": 25,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "topic_doc.reset_index().groupby('index').mean().idxmax()"
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_1</th>\n      <th>topic_2</th>\n      <th>topic_3</th>\n      <th>topic_4</th>\n      <th>topic_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>game</th>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>15.866</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>plai</th>\n      <td>0.120</td>\n      <td>0.000</td>\n      <td>6.753</td>\n      <td>0.020</td>\n      <td>1.230</td>\n    </tr>\n    <tr>\n      <th>time</th>\n      <td>1.805</td>\n      <td>1.620</td>\n      <td>4.003</td>\n      <td>1.220</td>\n      <td>0.986</td>\n    </tr>\n    <tr>\n      <th>player</th>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.932</td>\n      <td>1.481</td>\n      <td>0.186</td>\n    </tr>\n    <tr>\n      <th>world</th>\n      <td>0.617</td>\n      <td>1.577</td>\n      <td>2.871</td>\n      <td>0.939</td>\n      <td>0.527</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "        topic_1  topic_2  topic_3  topic_4  topic_5\ngame      0.000    0.000   15.866    0.000    0.000\nplai      0.120    0.000    6.753    0.020    1.230\ntime      1.805    1.620    4.003    1.220    0.986\nplayer    0.000    0.000    2.932    1.481    0.186\nworld     0.617    1.577    2.871    0.939    0.527"
                    },
                    "execution_count": 26,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "topic_word.T.sort_values(by='topic_3',ascending=False).head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "---\n### Machine Learning Foundation (C) 2020 IBM Corporation"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}